# 채점 모델 설명

본 문서는 Evaluation Server에서 사용하는  
자연어 처리 모델의 구성과 학습 방식을 설명합니다.

---

## 사용 모델

### 1. NLI 모델

- Base Model: klue/bert-base
- Task: Natural Language Inference
- Labels:
  - entailment
  - neutral
  - contradiction

NLI 모델은 사용자 답변과 모범 답변 간의  
논리적 관계를 판단하는 데 사용됩니다.

---

### 2. 임베딩 모델

- Model: BM-K/KoSimCSE-roberta-multitask
- Fine-tuning: 사용하지 않음

해당 모델은 다음 목적을 동시에 충족하기 위해 사용되었습니다.

- 문장 임베딩
- 단어(키워드) 임베딩
- 단일 모델 기반 유사도 계산

로컬 환경에서  
문장 임베딩 모델과 단어 임베딩 모델을 각각 운영하는 것이 부담된다고 판단하여,  
하나의 임베딩 모델로 채점 로직을 구성했습니다.

특히 단어 단위 임베딩에서도  
유사도 결과가 안정적으로 나타나  
키워드 포함 여부 판단에 적합하다고 판단했습니다.

---

## NLI 모델 학습 데이터

### KLUE-NLI (공식 데이터셋)

- 출처: Hugging Face Datasets Hub (`klue / nli`)
- 용도: 한국어 문장 간 기본적인 논리 추론 학습

---

### CS 도메인 추가 학습 데이터

CS 인터뷰 답변 특성을 반영하기 위해  
알고리즘, 자료구조, CS 개념 설명 문장을 중심으로  
약 1,500개의 문장 쌍을 직접 구성하여 추가 학습에 사용했습니다.

예시:

- Premise  
  배열의 탐색과 접근은 O(1)이지만, 중간 삽입과 삭제는 원소 이동으로 인해 O(n)입니다.

- Hypothesis  
  탐색과 접근은 O(1)이고, 삽입과 삭제는 O(n)입니다.

- Label  
  entailment

---

## 파인튜닝 전략

NLI 모델은 다음 단계로 학습되었습니다.

1. KLUE-NLI 데이터로 일반 NLI 학습
2. CS 도메인 데이터로 추가 미세 조정 (continued fine-tuning)

CS 데이터 학습 시에는  
저학습률(2e-6)을 사용하여  
기존 언어 추론 성능을 유지하면서 도메인 적응에 집중했습니다.

---

## 설계 판단

- 문장 유사도만으로는 논리적 오류를 탐지하기 어렵고
- 키워드 기반 방식만으로는 표현이 다른 정답을 놓칠 수 있습니다.

이를 보완하기 위해  
논리 관계 판단과 의미 기반 유사도 계산을 분리한 구조를 선택했습니다.
